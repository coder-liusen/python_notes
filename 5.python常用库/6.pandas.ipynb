{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas是数据分析最有用的库。  \n",
    "pandas的两种数据结构：Series和DataFrame。  \n",
    "Series是numpy.ndarray的子类，其相当于定长有序的字典。  \n",
    "Series的索引与字典的索引（键）的区别：  \n",
    "Series的索引与数据独立，字典的索引与数据不独立；Series索引可变，字典索引不可变；Series索引可重复，字典索引不可重复。  \n",
    "DataFrame相当于是多个Series（即其多列）对齐。所有Seiries共用一套索引，每个Series有一个名字（即列名）。  \n",
    "DataFrame的很多操作跟numpy中的数组类似，并且其很多方法也可以用于Series。  \n",
    "数据的一行称为一个记录；数据的一列称为一个字段。  \n",
    "  \n",
    "  \n",
    "  \n",
    " TODO：本笔记需要精心设置一些df的实例，以能够较好地展示DataFrame各种方法的效果。(比如：需要包括float、int、string以及NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame的创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) 一维数组dict + index\n",
    "dct = {'列1':[1,2,3],'列2':[1.1,2.2,3.3],'列3':[11,12,13]}\n",
    "df = pd.DataFrame(dct,index=['a','b','c'])\n",
    "print(df)\n",
    "\n",
    "# 注：dct中的数据，不是必须使用列表，也可以使用pandas支持的其他可迭代对象，比如元组、numpy一维数组、Series等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (2) 二维数组 + index + columns\n",
    "import numpy as np\n",
    "arr = np.random.rand(9).reshape(3,3)\n",
    "print(arr)\n",
    "df = pd.DataFrame(arr, index = [\"a\",\"b\",\"c\"], columns = [\"one\", \"two\", \"three\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (3) 字典list + index\n",
    "data = [{\"one\":1,\"two\":2},{\"one\":5,\"two\":10,\"three\":15}]\n",
    "df = pd.DataFrame(data,index = ['i1','i2'])\n",
    "print(df)\n",
    "\n",
    "# 注：该种方法亦可指定columns，但如果与data中的columns不同，则相应的取值为NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (4) 字典dict\n",
    "dct = {\n",
    "    \"Jack\":{\"math\":90, \"english\":89, \"art\":78},\n",
    "    \"Marry\":{\"math\":82, \"english\":95, \"art\":96},\n",
    "    \"Tom\":{\"math\":85, \"english\":94}\n",
    "}\n",
    "df = pd.DataFrame(dct)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "# (1) 查看头几行\n",
    "print(df.head(3))\n",
    "# (2) 查看尾几行\n",
    "print(df.tail(2))\n",
    "# (3) 查看索引名\n",
    "print(df.index)\n",
    "# (4) 查看字段名\n",
    "print(df.columns)\n",
    "# (5) 查看数据的值（数组）\n",
    "print(df.values)\n",
    "\n",
    "# 注：对df的index、columns、values的修改，只需要分别对df.index、df.columns、df.values重新赋值即可\n",
    "\n",
    "# (6) 查看数据规模\n",
    "print(df.shape)\n",
    "# (7) 查看数据类型\n",
    "print(df.dtypes)\n",
    "\n",
    "# (8) 查看统计信息\n",
    "print(df.describe())\n",
    "# (9) 查看基本信息\n",
    "print(df.info())\n",
    "\n",
    "df = pd.DataFrame({'a':[1,3,5,2,6,2,6,2,6,2,5,2,2,3,5],'b':[2,3,6,8,6,5,7,2,5,2,5,7,6,7,9]})\n",
    "\n",
    "# (10) 查看某一列数据包含多少不重复的值，以及每个值出现的次数\n",
    "print(df.b.value_counts())\n",
    "\n",
    "# (11) 另一种方法查看某一列数据包含多少不重复的值，但是不能看到每个值出现的次数\n",
    "print(df.b.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筛选数据\n",
    "对DataFrame数据的筛选，可以筛选一行/多行或一列/多列，也可以筛选一个值或者一个块；可以按照索引或列名筛选，也可以按照序号值筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "\n",
    "# (1) df['列名']：选择一列\n",
    "print(df['a'])\n",
    "\n",
    "# (2) df.列名：选择一列 （注意，这里列名不用加引号）\n",
    "print(df.a)\n",
    "# 注意，这种取一列数据的方法，只能用于列名为字符串类型，不能用于列名为int型\n",
    "\n",
    "# (3) df[start_ind : end_ind]：通过索引选择多行\n",
    "print(df[3:6])\n",
    "\n",
    "# (4) df[['列名1','列名2']]：选择多列，注意，多列的列名要用方括号（不能用圆括号）括起来，作成列表\n",
    "print(df[['c','b']])\n",
    "\n",
    "# 注意，df[] 的方式只能选择一列或者若干行，不能选择多列，也不能选择块。若需要选择多列或者块，则应使用.loc()的方式。\n",
    "\n",
    "# (5) df.loc[start_ind : end_ind , ('列名1','列名2',...)]：选择若干行若干列，通过索引值指定行，通过列名指定列\n",
    "print(df.loc[2:3,('b','c')])\n",
    "\n",
    "# (6) df.at[ind , '列名'] ：at只能选择某一行某一列位置处的一个值，通过索引值指定行，通过列名指定列\n",
    "print(df.at[3,'d'])\n",
    "\n",
    "# (7) df.iloc[start_sernum_r : end_sernum_r , start_sernum_c : end_sernum_c] ：选择若干行若干列，行和列都是通过序号值指定\n",
    "print(df.iloc[3:7,2:5])\n",
    "\n",
    "# (8) df.iat[sernum_r , sernum_c] ：只能选择某一行某一列位置处的一个值，行和列都是通过序号值指定\n",
    "print(df.iat[3,3])\n",
    "\n",
    "# 可以看出，loc、iloc用来筛选块数据，at、iat用来筛选单个数据；带i的是通过序号值指定数据范围，不带i的是通过索引值和列名指定数据范围\n",
    "\n",
    "# (9) 条件筛选： df[<constrain>]，其中constrain是用df['列名']约束的，表示某一列的数值中满足约束条件的数据\n",
    "# 并不是只选出这一列的数据，而是按照这一列的条件，选出所有的（整条）记录\n",
    "\n",
    "print(df[df.b>0.5])\n",
    "# df[df['列名'].str.contains('name')]： 筛选出在某一列中包含字符串'name'的记录\n",
    "# df[~ df['列名'].str.contains('name')]：筛选出在某一列中不包含字符串'name'的记录\n",
    "# df.select_dtypes(include='int64') #选取特定类型的字段数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重置索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.random.rand(9).reshape(3,3)\n",
    "df = pd.DataFrame(arr, index = [\"a\",\"b\",\"c\"], columns = [\"one\", \"two\", \"three\"])\n",
    "print(df)\n",
    "\n",
    " # (1) 直接用index_new替换df原来的索引，index_new可以是一个列表或其他可迭代对象\n",
    "index_new = ['d','e','f']\n",
    "df.index = index_new\n",
    "print(df)\n",
    "\n",
    "# (2) 用从0开始的自增序列替换原来的索引\n",
    "df.reset_index(drop = True) # drop = True是删除掉原来的索引，若不给这个参数，则原来的索引会变成新的df的一列\n",
    "print(df)\n",
    "\n",
    "# (3) 第三种方法与前两种重设索引的方式不同，前两种是新索引和老索引按长度对齐，然后对应地替换，\n",
    "# 但本方法是新索引和老索引按索引值对齐，然后替换，\n",
    "# 若新索引中含有老索引不曾有的索引值，那么该索引对应的数据全为空值，fill_value参数可以设置对这些空值用val进行填充\n",
    "val = 5\n",
    "index_new = ['a','b','d','e','f']\n",
    "print(df.reindex(index_new,fill_value = val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据设定（赋值）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.DataFrame(np.ones((9,5)),columns = ['a','b','c','d','e'])\n",
    "\n",
    "# (1) df['列名'] = s1 #将列名为“列名”的列设置为s1（s1是一个Series，也可以是list或者np.array）,\n",
    "# 但当s1为Series时，注意s1的索引应与df一致，否则df自动对齐，就会出现预期以外的效果\n",
    "\n",
    "# 注意对一列赋值时，不能使用df.列名，必须使用df['列名']。\n",
    "# df还有一些其他的用法也是只能筛选数据 ，而不能用来设定数据（只能作右值，不能作左值）。在实际中需要注意\n",
    "\n",
    "# (2) df.loc[ind1:ind2 , ('列名1','列名2',...)] = np.array(...) ：设置一块数据\n",
    "df.loc[2:3,['c','d']] = np.random.rand(4).reshape(2,2)\n",
    "\n",
    "# (3) df.at[ind,'列名'] = value ：设置一个数据\n",
    "df.at[3,'d'] = 100\n",
    "\n",
    "# (4) df['列名1'] = df.列名2.replace({'oldvalue1':'newvalue1' , 'oldvalue2':'newvalue2' , ...}) ：\n",
    "# 注意，replace方法的参数是一个字典；其中，“列名2”，也可以 =“列名1”\n",
    "df['c'] = df.c.replace({1:100,2:1000})\n",
    "print(df.c)\n",
    "\n",
    "# (5) df['列名1'] = df.列名2.replace([oldvalue1,oldvalue2,...],[newvalue1,newvalue2,...]) ：\n",
    "# replace可以接收两个列表作为参数，与接收字典的效果等价\n",
    "\n",
    "# (6) df.append(s, ignore_index=True) ：添加行：将s（s是一个Series）加到df的最后一行\n",
    "s = pd.Series([1,2,3,4,5],index = ['a','b','c','d','e'])\n",
    "df = df.append(s, ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(1) df.drop('列名',axis = 1) # 删除列：删除指定列名的一列\n",
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "df.drop('a',axis=1)\n",
    "print(df)\n",
    "\n",
    "# (2) df.drop(['列名1','列名2',...],axis = 1) # 删除列：删除指定列名的多列\n",
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "df.drop(['b','c'],axis=1)\n",
    "print(df)\n",
    "\n",
    "# (3) df.drop(line_num) ：删除行：删除索引号为line_num的一行，\n",
    "# 注意，删除列和删除行都是用 drop() 方法，但 drop() 默认axis = 0（即删除行），所以要想删除列，要特别指明axis = 1\n",
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "df = df.drop(3)\n",
    "print(df)\n",
    "\n",
    "# (4) df.drop(df_test[df_.列名 > 0.5].index) ：删除行（按条件删除）：删除在某一列中大于10的值所在的行\n",
    "df = df.drop(df[df.a > 0.5].index)\n",
    "print(df)\n",
    "\n",
    "# (5) df1 = df.drop_duplicates(inplace = False) ： 删除重复记录（按照全部字段判定是否重复）\n",
    "\n",
    "# (6) df1 = df.drop_duplicates(subset = lst , inplace = False) ： 也是删除重复记录，但是可以按照部分字段判断是否重复，其中lst是部分字段的字段名列表\n",
    "\n",
    "# 注意，df的很多方法并不改变原来的数据（包括drop方法），而是返回改变后的数据，但将参数inplace设置为True，就会在原来的数据上改变 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 列的类型转换\n",
    "df的一列的类型是Series，可以将其转换成list或者np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "# (1) df.列名.to_list() ： 转成list\n",
    "lst = df.b.to_list()\n",
    "print(lst)\n",
    "print(type(lst))\n",
    "# (2) df.列名.to_numpy() ： 转成np.array\n",
    "narr = df.b.to_numpy()\n",
    "print(narr)\n",
    "print(type(narr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "# (1) pd.isna(df) ：找出df中哪些元素是空值\n",
    "\n",
    "# (2) df.isnull() ：也是找出df中哪些元素是空值\n",
    "\n",
    "# (3) df.dropna(how = 'any') ：删除空值（该参数下，删除空值所在的行）\n",
    "\n",
    "# (4) df.fillna(value = 5) ：填充空值\n",
    "\n",
    "# (5) df[df.isnull().values]：选取df中所有存在空值的记录（条件筛选）, 注意不是df[df.isnull()]\n",
    "\n",
    "# (6) df.isnull().sum()[lambda x: x>0] ：查看所有存在空值的字段和每个字段的空值个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "# (1) df.sum() ：求和（默认按列）\n",
    "print(df.sum())\n",
    "# (2) df.sum(axis = 1) #指定axis = 1，即按行求和，（其他统计函数也是这样，默认都是按列统计，通过axis可以指定按行还是按列求和）\n",
    "print(df.sum(axis = 1))\n",
    "# (3) df.mean() ：求均值\n",
    "print(df.mean())\n",
    "# (4) df.median() ：求中值\n",
    "print(df.median())\n",
    "# (5) df.min() ：求最小值\n",
    "print(df.min())\n",
    "# (6) df.max() ：求最大值\n",
    "print(df.max())\n",
    "\n",
    "# 注意，以上统计函数都也可用于某一列，如：\n",
    "print(df.a.sum())\n",
    "print(df.a.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 列的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.列名1 + df.列名2 ：两列相加，对应元素相加，返回一个Series\n",
    "# df.列名1 - df.列名2 ：两列相减，对应元素相减，返回一个Series\n",
    "# df.列名1 * df.列名2 ：两列相乘，对应元素相乘，返回一个Series\n",
    "# df.列名1 / df.列名2 ：两列相除，对应元素相除，返回一个Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.列名.sort_values(ascending = True)：对某一列进行排序，可以设置升序还是降序\n",
    "# df.sort_values(by = '列名',ascending = True)：与上面的功能一样，也是对某一列进行排序\n",
    "# df.sort_values(by = ['列名1','列名2'],ascending = [True,False])：还可以对多列进行排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) concat,合并一个列表中各df\n",
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "pieces = [df[:3], df[3:7], df[7:]]\n",
    "print(pd.concat(pieces))\n",
    "\n",
    "## (2) merge，类似sql中的多表连接\n",
    "left = pd.DataFrame({'key': ['foo', 'foo'], 'lval': [1, 2]})\n",
    "right = pd.DataFrame({'key': ['foo', 'foo'], 'rval': [4, 5]})\n",
    "print(pd.merge(left, right, on='key'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分组统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('A').sum() ：按照字段A计算求和（类似于sql中的分组+聚合函数），会自动去掉不可求和字段，也可以按多个字段分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## (1) 转置\n",
    "df = pd.DataFrame(np.random.randn(10, 4))\n",
    "print(df.T) #实现行列互换，原索引变成字段，原字段变成索引\n",
    "\n",
    "## (2) 堆叠\n",
    "tuples = list(zip(['bar', 'bar', 'baz', 'baz',\n",
    "'foo', 'foo', 'qux', 'qux'],\n",
    "['one', 'two', 'one', 'two',\n",
    "'one', 'two', 'one', 'two'])) \n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second']) # 用tuple生成一个两级索引\n",
    "df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B']) # 基于两级索引生成df\n",
    "\n",
    "stacked = df.stack() # 堆叠，将二维数据df变为一维数据（即将字段的值变成索引！）\n",
    "stacked.unstack() # stack的逆操作\n",
    "\n",
    "## (3) 透视表（类似Excel中的透视表，即从数据源中选取行字段、列字段、值字段，构成透视表）\n",
    "df = pd.DataFrame({'A': ['one', 'one', 'two', 'three'] * 3,\n",
    "'B': ['A', 'B', 'C'] * 4,\n",
    "'C': ['foo', 'foo', 'foo', 'bar', 'bar', 'bar'] * 2,\n",
    "'D': np.random.randn(12),\n",
    "'E': np.random.randn(12)}) # 定义数据\n",
    "\n",
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C']) # 生成透视表（需指定值字段、行字段、列字段）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) 创建时间索引，并用时间索引创建Series\n",
    "rng = pd.date_range('1/1/2019', periods=100, freq='S') # 生成时间索引\n",
    "print(rng[:5])\n",
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng) # 将时间索引作为索引，生成Series\n",
    "print(ts.head())\n",
    "\n",
    "# (2) 对ts重采样并进行数据整合\n",
    "ts1 = ts.resample('10s')\n",
    "print(ts1.mean())\n",
    "\n",
    "ts_utc = ts.tz_localize('UTC') # 显示时区\n",
    "ts_utc.tz_convert('US/Eastern') # 转换时区\n",
    "\n",
    "# (3) 时间格式转换\n",
    "rng = pd.date_range('1/1/2019', periods=5, freq='M') # 以月份为间隔生成时间索引\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng) # 生成Series\n",
    "ps = ts.to_period() # 格式转换\n",
    "print(ps)\n",
    "ps = ps.to_timestamp() # 格式转换\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分类目录类型：（Categoricals）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"id\": [1, 2, 3, 4, 5, 6],\n",
    "\"raw_grade\": ['a', 'b', 'b', 'a', 'a', 'e']})\n",
    "\n",
    "# (1) 将一个离散数值的字段的类型改为“Cateory”类型，该类型的字段可以进行关于分类的一些操作\n",
    "df['grade'] = df['raw_grade'].astype('category')\n",
    "print(df.grade)\n",
    "\n",
    "# (2) 该字段类型改为category后，可以使用cat方法对它的值重命名\n",
    "df[\"grade\"].cat.categories = [\"very good\", \"good\", \"very bad\"]\n",
    "print(df.grade)\n",
    "\n",
    "# (3) 对该字段进行排序\n",
    "print(df.sort_values(by=\"grade\"))\n",
    "\n",
    "# (4) 对该字段进行分组\n",
    "print(df.groupby(\"grade\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame常用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) map()：\n",
    "# map()方法接收字典作为参数，按照字典中定义的规则将df的一列映射为一个Series。\n",
    "# df['列名1'] = df.列名2.map({'oldvalue1':'newvalue1' , 'oldvalue2':'newvalue2' , ...}) # 其中，列名2也可以=列名1\n",
    "\n",
    "# 注意，上文中介绍了replace()方法。map()和replace()的异同：二者都是接收字典作为参数，按照字典中的键值对原列中相应数据进行替换，\n",
    "# 但replace对原列数据中没有在字典中出现的值会保持不变，而map对原列数据中没有在字典中出现的值会填充NaN。\n",
    "\n",
    "# (2) apply()：\n",
    "# apply()方法是pandas中最重要的方法，因为它可以接收很多的方法、包括python内置方法、numpy中的方法和自定义的方法，非常灵活。\n",
    "df = pd.DataFrame(np.random.rand(45).reshape(9,5),columns = ['a','b','c','d','e'])\n",
    "print(df.apply(np.cumsum,axis = 1)) # apply可以按列计算，也可以按行计算，只需将axis设置为1或0即可\n",
    "print(df.a.apply(lambda x: x**2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入导出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) CSV\n",
    "# df.to_csv('foo.csv') # 写入\n",
    "# pd.read_csv('foo.csv') # 读取\n",
    "\n",
    "## (2) Excel\n",
    "# df.to_excel('foo.xlsx', sheet_name='Sheet1') # 写入\n",
    "# pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA']) # 读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) pandas中DataFrame对象的head()方法，行或列显示不全的解决方案\n",
    "pd.set_option('display.max_columns', None) #显示所有列\n",
    "pd.set_option('display.max_rows', None) #显示所有行\n",
    "\n",
    "# 这种处理方式感觉有点像“猴子补丁”的思想。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
